{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171367ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import DeepGraphInfomax\n",
    "from torch_geometric.utils import to_undirected, add_remaining_self_loops\n",
    "from ogb.nodeproppred import PygNodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(x, K=-1, Niter=10, verbose=False):\n",
    "    #start = time.time()\n",
    "    N, D = x.shape  # Number of samples, dimension of the ambient space\n",
    "    x_temp = x.detach()\n",
    "\n",
    "    temp = set()\n",
    "    while len(temp)<K:\n",
    "        temp.add(np.random.randint(0, N))\n",
    "    c = x_temp[list(temp), :].clone()\n",
    "\n",
    "    x_i = x_temp.view(N, 1, D) # (N, 1, D) samples\n",
    "    cutoff = 1\n",
    "    if K>cutoff:\n",
    "        c_j = []\n",
    "        niter=K//cutoff\n",
    "        rem = K%cutoff\n",
    "        if rem>0:\n",
    "            rem=1\n",
    "        for i in range(niter+rem):\n",
    "            c_j.append(c[i*cutoff:min(K,(i+1)*cutoff),:].view(1, min(K,(i+1)*cutoff)-(i*cutoff), D))\n",
    "    else:\n",
    "        c_j = c.view(1, K, D) # (1, K, D) centroids\n",
    "\n",
    "    # K-means loop:\n",
    "    # - x  is the (N, D) point cloud,\n",
    "    # - cl is the (N,) vector of class labels\n",
    "    # - c  is the (K, D) cloud of cluster centroids\n",
    "    for i in range(Niter):\n",
    "        #print(\"iteration: \" + str(i))\n",
    "\n",
    "        # E step: assign points to the closest cluster -------------------------\n",
    "        if K>cutoff:\n",
    "            for j in range(len(c_j)):\n",
    "                if j==0:\n",
    "                    D_ij = ((x_i - c_j[j]) ** 2).sum(-1)\n",
    "                else:\n",
    "                    D_ij = torch.cat((D_ij,((x_i - c_j[j]) ** 2).sum(-1)), dim=-1)\n",
    "                    # D_ij += ((x_i - c_j[j]) ** 2).sum(-1)\n",
    "        else:\n",
    "            D_ij = ((x_i - c_j) ** 2).sum(-1)  # (N, K) symbolic squared distances\n",
    "        assert D_ij.size(1)==K\n",
    "        cl = D_ij.argmin(dim=1).long().view(-1)  # Points -> Nearest cluster\n",
    "        c.zero_()\n",
    "        c.scatter_add_(0, cl[:, None].repeat(1, D), x_temp)\n",
    "\n",
    "        # Divide by the number of points per cluster:\n",
    "        Ncl = torch.bincount(cl, minlength=K).type_as(c).view(K, 1)\n",
    "        # print(Ncl[:10])\n",
    "        Ncl += 0.00000000001\n",
    "        c /= Ncl  # in-place division to compute the average\n",
    "    return cl, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb884f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39644c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = \"/home/devvrit_03/GraphNN/clean_codes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4603f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.load(direct+\"edge_index_papers100M.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborSampler(edge_index, node_idx=None,\n",
    "                               sizes=[25, 15, 7], batch_size=2048,\n",
    "                               shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ef617",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = NeighborSampler(edge_index, node_idx=indices,\n",
    "                              sizes=[25, 15, 7], batch_size=2048,\n",
    "                              shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "del edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(direct+\"x_papers100M.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.load(direct+\"y_papers100M.pt\")\n",
    "indices = torch.load(direct+\"indices_papers100M.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3239717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            SAGEConv(in_channels, hidden_channels),\n",
    "            SAGEConv(hidden_channels, hidden_channels),\n",
    "            SAGEConv(hidden_channels, hidden_channels)\n",
    "        ])\n",
    "\n",
    "        self.activations = torch.nn.ModuleList()\n",
    "        self.activations.extend([\n",
    "            nn.PReLU(hidden_channels),\n",
    "            nn.PReLU(hidden_channels),\n",
    "            nn.PReLU(hidden_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            x = self.activations[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corruption(x, edge_index):\n",
    "    return x[torch.randperm(x.size(0))], edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepGraphInfomax(\n",
    "    hidden_channels=512, encoder=Encoder(x.size(-1), 512),\n",
    "    summary=lambda z, *args, **kwargs: torch.sigmoid(z.mean(dim=0)),\n",
    "    corruption=corruption).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf64177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    it = 0\n",
    "    best_nmi=-1\n",
    "    for batch_size, n_id, adjs in tqdm(train_loader,\n",
    "                                       desc=f'Epoch {epoch:02d}'):\n",
    "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "        model.train()\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x[n_id].to(device), adjs)\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pos_z.size(0)\n",
    "        total_examples += pos_z.size(0)\n",
    "        it+=1\n",
    "        del pos_z,neg_z,summary,loss\n",
    "        if it%10==0:\n",
    "            y_gt = []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                zs = []\n",
    "                #for i, (batch_size, n_id, adjs) in enumerate(test_loader):\n",
    "                for batch_size, n_id, adjs in tqdm(test_loader, desc=f'Test niter {it:02d}'):\n",
    "                    adjs = [adj.to(device) for adj in adjs]\n",
    "                    zs.append(model(x[n_id].to(device), adjs)[0])\n",
    "                    y_gt = y_gt + y[n_id[:batch_size]].tolist()\n",
    "                zs = torch.cat(zs, dim=0)\n",
    "                zs = torch.nn.functional.normalize(zs)\n",
    "                y_pred,_ = Kmeans(zs, y[indices].max()+1)\n",
    "            nmi = metrics.normalized_mutual_info_score(np.array(y_gt), y_pred.cpu().numpy())\n",
    "            if nmi>best_nmi:\n",
    "                best_nmi=nmi\n",
    "                torch.save(zs, \"embedding_metis_papers100M.pt\")\n",
    "            print(\"epoch: \" + str(epoch) + \", iter= \"+str(it)+\", nmi: \" + str(round(nmi, 5))+\", best_nmi= \" + str(round(best_nmi,5)))\n",
    "            torch.save(torch.tensor(y_gt), \"y_gt_papers100M.pt\")\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1bfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 21):\n",
    "    model.train()\n",
    "    loss = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}')\n",
    "    # test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6aafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
